{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/rutuja/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/rutuja/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/rutuja/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from csv import reader\n",
    "import re\n",
    "import spacy\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "\n",
    "with open('vocabulary.txt', 'rb') as handle:\n",
    "    vocabulary = pickle.loads(handle.read())\n",
    "    \n",
    "with open('logprior.txt', 'rb') as handle:\n",
    "    logprior = pickle.loads(handle.read())\n",
    "    \n",
    "with open('logLikelihoodPositive.txt', 'rb') as handle:\n",
    "    logLikelihoodPositive = pickle.loads(handle.read())\n",
    "    \n",
    "with open('logLikelihoodNegative.txt', 'rb') as handle:\n",
    "    logLikelihoodNegative = pickle.loads(handle.read())\n",
    "\n",
    "    \n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags = re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+|\\#', \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z. ]\",\"\",text)\n",
    "    text = re.sub(r'\\.+', \".\",text)\n",
    "    text_tokens = word_tokenize(text)\n",
    "    filtered_words = [word for word in text_tokens if word not in stop_words]\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_words = [ps.stem(w) for w in filtered_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_words = [lemmatizer.lemmatize(w, pos='a') for w in stemmed_words]  \n",
    "    return \" \".join(lemma_words)\n",
    "\n",
    "    \n",
    "my_dict ={}\n",
    "actualArray =[]\n",
    "predictedArray = []\n",
    "    \n",
    "with open('TestDataset - Sheet1.csv', 'r') as read_obj:\n",
    "    csv_reader = reader(read_obj)\n",
    "    next(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        row[1] = row[1].split(',')\n",
    "        actualArray.append(row[3])\n",
    "        my_dict[row[0]] = []\n",
    "        with open(row[4],'r') as file:\n",
    "            sentence = file.read()\n",
    "        sentences = sentence.split('.')\n",
    "        for sentence in sentences:\n",
    "            doc = nlp(sentence)\n",
    "            for ent in doc.ents:\n",
    "                if ent.text in row[1]:\n",
    "                    sentence = preprocess_text(sentence)\n",
    "                    my_dict[row[0]].append(sentence)\n",
    "\n",
    "# print(my_dict['Tony Stark'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony Stark\n",
      "Gabbar\n",
      "Sauron\n",
      "Khilji\n",
      "Bhallaladeva\n",
      "Amit Shellar\n",
      "Gandalf\n",
      "Raju\n",
      "Mogambo\n",
      "Kancha\n",
      "Kaal\n",
      "Loki\n",
      "Thanos\n",
      "Peter Parker\n",
      "Valentine\n",
      "Venom\n",
      "Otto Octavius\n",
      "Scar\n",
      "Simba\n",
      "Lady Tremaine\n",
      "Shere Khan\n",
      "Mowgli\n",
      "Sid Phillips\n",
      "Woody\n",
      "Evelyn\n",
      "Bob\n",
      "Dolores Umbridge\n",
      "Robert Callaghan\n",
      "Jafar\n",
      "Gaston\n",
      "Elsa\n",
      "Maleficent\n",
      "al Ghul\n",
      "Kaecilius\n",
      "Strange\n",
      "Batman\n",
      "Harry\n",
      "Amarendra Bahubali\n",
      "Bilbo Baggins\n",
      "Thor\n",
      "Saruman\n",
      "Frodo\n",
      "Farhan\n",
      "Louisa\n",
      "Biff Tannen\n",
      "Hans Gruber\n",
      "Chucky\n",
      "Jack Dawson\n",
      "William\n",
      "Mark Watney\n",
      "Rhett\n",
      "Jim\n",
      "Forrest\n",
      "Mia\n",
      "Simran\n",
      "Hazel\n",
      "Holmes\n",
      "John Watson\n",
      "Tim\n",
      "Mary\n",
      "correct predictions are\n",
      "33\n",
      "accuracy is \n",
      "0.55\n",
      "{'Tony Stark': 'good', 'Gabbar': 'evil', 'Sauron': 'good', 'Khilji': 'good', 'Bhallaladeva': 'evil', 'Amit Shellar': 'good', 'Gandalf': 'good', 'Raju': 'evil', 'Mogambo': 'evil', 'Kancha': 'good', 'Kaal': 'evil', 'Loki': 'evil', 'Thanos': 'evil', 'Peter Parker': 'good', 'Valentine': 'evil', 'Venom': 'good', 'Otto Octavius': 'good', 'Scar': 'good', 'Simba': 'good', 'Lady Tremaine': 'good', 'Shere Khan': 'good', 'Mowgli': 'good', 'Sid Phillips': 'evil', 'Woody': 'evil', 'Evelyn': 'evil', 'Bob': 'evil', 'Dolores Umbridge': 'good', 'Robert Callaghan': 'evil', 'Jafar': 'good', 'Gaston': 'evil', 'Elsa': 'good', 'Maleficent': 'good', 'al Ghul': 'evil', 'Kaecilius': 'good', 'Strange': 'evil', 'Batman': 'good', 'Harry': 'good', 'Amarendra Bahubali': 'evil', 'Bilbo Baggins': 'evil', 'Thor': 'evil', 'Saruman': 'good', 'Frodo': 'good', 'Farhan': 'evil', 'Louisa': 'evil', 'Biff Tannen': 'good', 'Hans Gruber': 'good', 'Chucky': 'good', 'Jack Dawson': 'good', 'William': 'good', 'Mark Watney': 'evil', 'Rhett': 'good', 'Jim': 'good', 'Forrest': 'good', 'Mia': 'evil', 'Simran': 'evil', 'Hazel': 'good', 'Holmes': 'good', 'John Watson': 'good', 'Tim': 'good', 'Mary': 'good'}\n"
     ]
    }
   ],
   "source": [
    "final_dict = {}\n",
    "\n",
    "\n",
    "for character in my_dict:\n",
    "    print(character)\n",
    "    positiveSentences = 0\n",
    "    negativeSentences = 0\n",
    "    for sentence in my_dict[character]:\n",
    "        sumPositive = logprior[\"positive\"]\n",
    "        sumNegative = logprior[\"negative\"] \n",
    "#         words = sentence.split(\" \")\n",
    "        words = sentence.split(\" \") \n",
    "      \n",
    "        for word in words:           \n",
    "            if word in vocabulary:\n",
    "                sumPositive = sumPositive + logLikelihoodPositive[word]\n",
    "                sumNegative = sumNegative + logLikelihoodNegative[word]\n",
    "      \n",
    "        if abs(sumPositive - sumNegative) >= 0:\n",
    "            if sumPositive> sumNegative:\n",
    "                positiveSentences = positiveSentences + 1\n",
    "            else:\n",
    "                negativeSentences = negativeSentences + 1\n",
    "   \n",
    "    total = positiveSentences + negativeSentences\n",
    "    if negativeSentences >= 0.30*total:\n",
    "        final_dict[character] = \"evil\"\n",
    "    else:\n",
    "        final_dict[character] = \"good\"\n",
    "    predictedArray.append(final_dict[character]) \n",
    "    \n",
    "\n",
    "\n",
    "correct = 0\n",
    "length = len(actualArray)\n",
    "for i in range(length):\n",
    "    if actualArray[i]==predictedArray[i]:\n",
    "        correct = correct + 1\n",
    "      \n",
    "\n",
    "        \n",
    "accuracy = correct/length \n",
    "print(\"correct predictions are\")\n",
    "print(correct)\n",
    "print(\"accuracy is \")\n",
    "print(accuracy)\n",
    "\n",
    "print(final_dict)  \n",
    "\n",
    "final_dict ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
